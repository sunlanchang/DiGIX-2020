{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-09-17 11:18:31] - __init__.py[line:127] - INFO: Successfully Reload: /home/tione/notebook/huawei/cached_data/CACHE_dataall0816.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label                          float64\n",
      "uid                              int32\n",
      "task_id                          int16\n",
      "adv_id                           int16\n",
      "creat_type_cd                     int8\n",
      "adv_prim_id                      int16\n",
      "dev_id                            int8\n",
      "inter_type_cd                     int8\n",
      "slot_id                           int8\n",
      "spread_app_id                     int8\n",
      "tags                              int8\n",
      "app_first_class                   int8\n",
      "app_second_class                  int8\n",
      "age                               int8\n",
      "city                             int16\n",
      "city_rank                         int8\n",
      "device_name                       int8\n",
      "device_size                      int16\n",
      "career                            int8\n",
      "gender                            int8\n",
      "net_type                          int8\n",
      "residence                         int8\n",
      "his_app_size                      int8\n",
      "his_on_shelf_time                 int8\n",
      "app_score                         int8\n",
      "emui_dev                          int8\n",
      "list_time                         int8\n",
      "device_price                      int8\n",
      "up_life_duration                  int8\n",
      "up_membership_grade               int8\n",
      "membership_life_duration          int8\n",
      "consume_purchase                  int8\n",
      "communication_onlinerate        object\n",
      "communication_avgonline_30d       int8\n",
      "indu_name                         int8\n",
      "pt_d                              int8\n",
      "id                               int32\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-09-17 11:18:56] - __init__.py[line:127] - INFO: Successfully Reload: /home/tione/notebook/huawei/cached_data/CACHE_cmr0816.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00000    1029455\n",
      "1.00000     205891\n",
      "Name: label, dtype: int64 0.16666666666666666\n",
      "0.00000    877110\n",
      "1.00000    175422\n",
      "Name: label, dtype: int64 0.16666666666666666\n",
      "0.00000    896355\n",
      "1.00000    179271\n",
      "Name: label, dtype: int64 0.16666666666666666\n",
      "0.00000    853630\n",
      "1.00000    170726\n",
      "Name: label, dtype: int64 0.16666666666666666\n",
      "0.00000    813915\n",
      "1.00000    162783\n",
      "Name: label, dtype: int64 0.16666666666666666\n",
      "0.00000    932075\n",
      "1.00000    186415\n",
      "Name: label, dtype: int64 0.16666666666666666\n",
      "2731.54 Mb, 746.46 Mb (72.67 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-09-17 11:23:32] - __init__.py[line:112] - INFO: Cache Successfully! File name: /home/tione/notebook/huawei/cached_data/CACHE_data_step_1_feature_0917_r5.pkl\n",
      "100%|██████████| 44/44 [00:02<00:00, 18.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['uid', 'pt_d', 'creat_type_cd', 'creat_type_cd_count', 'creat_type_cd_pt_d_count'], dtype='object')\n",
      "Index(['uid', 'pt_d', 'task_id', 'task_id_count', 'task_id_pt_d_count'], dtype='object')\n",
      "Index(['uid', 'pt_d', 'dev_id', 'dev_id_count', 'dev_id_pt_d_count'], dtype='object')\n",
      "Index(['uid', 'pt_d', 'slot_id', 'slot_id_count', 'slot_id_pt_d_count'], dtype='object')\n",
      "Index(['uid', 'pt_d', 'tags', 'tags_count', 'tags_pt_d_count'], dtype='object')\n",
      "Index(['uid', 'pt_d', 'app_second_class', 'app_second_class_count', 'app_second_class_pt_d_count'], dtype='object')\n",
      "Index(['uid', 'pt_d', 'device_name', 'device_name_count', 'device_name_pt_d_count'], dtype='object')\n",
      "Index(['uid', 'pt_d', 'gender', 'gender_count', 'gender_pt_d_count'], dtype='object')\n",
      "Index(['uid', 'pt_d', 'residence', 'residence_count', 'residence_pt_d_count'], dtype='object')\n",
      "Index(['uid', 'pt_d', 'indu_name', 'indu_name_count', 'indu_name_pt_d_count'], dtype='object')\n",
      "Index(['uid', 'pt_d', 'adv_prim_id', 'adv_prim_id_count', 'adv_prim_id_pt_d_count'], dtype='object')\n",
      "Index(['uid', 'pt_d', 'inter_type_cd', 'inter_type_cd_count', 'inter_type_cd_pt_d_count'], dtype='object')\n",
      "Index(['uid', 'pt_d', 'spread_app_id', 'spread_app_id_count', 'spread_app_id_pt_d_count'], dtype='object')\n",
      "Index(['uid', 'pt_d', 'app_first_class', 'app_first_class_count', 'app_first_class_pt_d_count'], dtype='object')\n",
      "Index(['uid', 'pt_d', 'adv_id', 'adv_id_count', 'adv_id_pt_d_count'], dtype='object')\n",
      "Index(['uid', 'pt_d', 'city', 'city_count', 'city_pt_d_count'], dtype='object')\n",
      "Index(['uid', 'pt_d', 'career', 'career_count', 'career_pt_d_count'], dtype='object')\n",
      "Index(['uid', 'pt_d', 'net_type', 'net_type_count', 'net_type_pt_d_count'], dtype='object')\n",
      "Index(['uid', 'pt_d', 'emui_dev', 'emui_dev_count', 'emui_dev_pt_d_count'], dtype='object')\n",
      "Index(['uid', 'pt_d', 'cmr_0', 'cmr_0_count', 'cmr_0_pt_d_count'], dtype='object')\n",
      "Index(['uid', 'pt_d', 'cmr_1', 'cmr_1_count', 'cmr_1_pt_d_count'], dtype='object')\n",
      "Index(['uid', 'pt_d', 'cmr_3', 'cmr_3_count', 'cmr_3_pt_d_count'], dtype='object')\n",
      "Index(['uid', 'pt_d', 'cmr_5', 'cmr_5_count', 'cmr_5_pt_d_count'], dtype='object')\n",
      "Index(['uid', 'pt_d', 'cmr_2', 'cmr_2_count', 'cmr_2_pt_d_count'], dtype='object')\n",
      "\n",
      "Index(['uid', 'pt_d', 'cmr_7', 'cmr_7_count', 'cmr_7_pt_d_count'], dtype='object')Index(['uid', 'pt_d', 'cmr_4', 'cmr_4_count', 'cmr_4_pt_d_count'], dtype='object')\n",
      "Index(['uid', 'pt_d', 'cmr_9', 'cmr_9_count', 'cmr_9_pt_d_count'], dtype='object')\n",
      "Index(['uid', 'pt_d', 'cmr_6', 'cmr_6_count', 'cmr_6_pt_d_count'], dtype='object')\n",
      "Index(['uid', 'pt_d', 'cmr_11', 'cmr_11_count', 'cmr_11_pt_d_count'], dtype='object')\n",
      "Index(['uid', 'pt_d', 'cmr_8', 'cmr_8_count', 'cmr_8_pt_d_count'], dtype='object')\n",
      "Index(['uid', 'pt_d', 'cmr_13', 'cmr_13_count', 'cmr_13_pt_d_count'], dtype='object')\n",
      "Index(['uid', 'pt_d', 'cmr_10', 'cmr_10_count', 'cmr_10_pt_d_count'], dtype='object')\n",
      "Index(['uid', 'pt_d', 'cmr_15', 'cmr_15_count', 'cmr_15_pt_d_count'], dtype='object')\n",
      "Index(['uid', 'pt_d', 'cmr_12', 'cmr_12_count', 'cmr_12_pt_d_count'], dtype='object')\n",
      "Index(['uid', 'pt_d', 'cmr_17', 'cmr_17_count', 'cmr_17_pt_d_count'], dtype='object')\n",
      "Index(['uid', 'pt_d', 'cmr_14', 'cmr_14_count', 'cmr_14_pt_d_count'], dtype='object')\n",
      "Index(['uid', 'pt_d', 'cmr_19', 'cmr_19_count', 'cmr_19_pt_d_count'], dtype='object')\n",
      "Index(['uid', 'pt_d', 'cmr_16', 'cmr_16_count', 'cmr_16_pt_d_count'], dtype='object')\n",
      "Index(['uid', 'pt_d', 'cmr_21', 'cmr_21_count', 'cmr_21_pt_d_count'], dtype='object')\n",
      "Index(['uid', 'pt_d', 'cmr_18', 'cmr_18_count', 'cmr_18_pt_d_count'], dtype='object')\n",
      "Index(['uid', 'pt_d', 'cmr_23', 'cmr_23_count', 'cmr_23_pt_d_count'], dtype='object')\n",
      "Index(['uid', 'pt_d', 'cmr_20', 'cmr_20_count', 'cmr_20_pt_d_count'], dtype='object')\n",
      "Index(['uid', 'pt_d', 'cmr_22', 'cmr_22_count', 'cmr_22_pt_d_count'], dtype='object')\n",
      "Index(['uid', 'pt_d', 'age', 'age_count', 'age_pt_d_count'], dtype='object')\n",
      "Index(['task_id_count', 'task_id_pt_d_count'], dtype='object') task_id (8601298, 65)\n",
      "Index(['adv_id_count', 'adv_id_pt_d_count'], dtype='object') adv_id (8601298, 67)\n",
      "Index(['creat_type_cd_count', 'creat_type_cd_pt_d_count'], dtype='object') creat_type_cd (8601298, 69)\n",
      "Index(['adv_prim_id_count', 'adv_prim_id_pt_d_count'], dtype='object') adv_prim_id (8601298, 71)\n",
      "Index(['dev_id_count', 'dev_id_pt_d_count'], dtype='object') dev_id (8601298, 73)\n",
      "Index(['inter_type_cd_count', 'inter_type_cd_pt_d_count'], dtype='object') inter_type_cd (8601298, 75)\n",
      "Index(['slot_id_count', 'slot_id_pt_d_count'], dtype='object') slot_id (8601298, 77)\n",
      "Index(['spread_app_id_count', 'spread_app_id_pt_d_count'], dtype='object') spread_app_id (8601298, 79)\n",
      "Index(['tags_count', 'tags_pt_d_count'], dtype='object') tags (8601298, 81)\n",
      "Index(['app_first_class_count', 'app_first_class_pt_d_count'], dtype='object') app_first_class (8601298, 83)\n",
      "Index(['app_second_class_count', 'app_second_class_pt_d_count'], dtype='object') app_second_class (8601298, 85)\n",
      "Index(['city_count', 'city_pt_d_count'], dtype='object') city (8601298, 87)\n",
      "Index(['device_name_count', 'device_name_pt_d_count'], dtype='object') device_name (8601298, 89)\n",
      "Index(['career_count', 'career_pt_d_count'], dtype='object') career (8601298, 91)\n",
      "Index(['gender_count', 'gender_pt_d_count'], dtype='object') gender (8601298, 93)\n",
      "Index(['net_type_count', 'net_type_pt_d_count'], dtype='object') net_type (8601298, 95)\n",
      "Index(['residence_count', 'residence_pt_d_count'], dtype='object') residence (8601298, 97)\n",
      "Index(['emui_dev_count', 'emui_dev_pt_d_count'], dtype='object') emui_dev (8601298, 99)\n",
      "Index(['indu_name_count', 'indu_name_pt_d_count'], dtype='object') indu_name (8601298, 101)\n",
      "Index(['cmr_0_count', 'cmr_0_pt_d_count'], dtype='object') cmr_0 (8601298, 103)\n",
      "Index(['cmr_1_count', 'cmr_1_pt_d_count'], dtype='object') cmr_1 (8601298, 105)\n",
      "Index(['cmr_2_count', 'cmr_2_pt_d_count'], dtype='object') cmr_2 (8601298, 107)\n",
      "Index(['cmr_3_count', 'cmr_3_pt_d_count'], dtype='object') cmr_3 (8601298, 109)\n",
      "Index(['cmr_4_count', 'cmr_4_pt_d_count'], dtype='object') cmr_4 (8601298, 111)\n",
      "Index(['cmr_5_count', 'cmr_5_pt_d_count'], dtype='object') cmr_5 (8601298, 113)\n",
      "Index(['cmr_6_count', 'cmr_6_pt_d_count'], dtype='object') cmr_6 (8601298, 115)\n",
      "Index(['cmr_7_count', 'cmr_7_pt_d_count'], dtype='object') cmr_7 (8601298, 117)\n",
      "Index(['cmr_8_count', 'cmr_8_pt_d_count'], dtype='object') cmr_8 (8601298, 119)\n",
      "Index(['cmr_9_count', 'cmr_9_pt_d_count'], dtype='object') cmr_9 (8601298, 121)\n",
      "Index(['cmr_10_count', 'cmr_10_pt_d_count'], dtype='object') cmr_10 (8601298, 123)\n",
      "Index(['cmr_11_count', 'cmr_11_pt_d_count'], dtype='object') cmr_11 (8601298, 125)\n",
      "Index(['cmr_12_count', 'cmr_12_pt_d_count'], dtype='object') cmr_12 (8601298, 127)\n",
      "Index(['cmr_13_count', 'cmr_13_pt_d_count'], dtype='object') cmr_13 (8601298, 129)\n",
      "Index(['cmr_14_count', 'cmr_14_pt_d_count'], dtype='object') cmr_14 (8601298, 131)\n",
      "Index(['cmr_15_count', 'cmr_15_pt_d_count'], dtype='object') cmr_15 (8601298, 133)\n",
      "Index(['cmr_16_count', 'cmr_16_pt_d_count'], dtype='object') cmr_16 (8601298, 135)\n",
      "Index(['cmr_17_count', 'cmr_17_pt_d_count'], dtype='object') cmr_17 (8601298, 137)\n",
      "Index(['cmr_18_count', 'cmr_18_pt_d_count'], dtype='object') cmr_18 (8601298, 139)\n",
      "Index(['cmr_19_count', 'cmr_19_pt_d_count'], dtype='object') cmr_19 (8601298, 141)\n",
      "Index(['cmr_20_count', 'cmr_20_pt_d_count'], dtype='object') cmr_20 (8601298, 143)\n",
      "Index(['cmr_21_count', 'cmr_21_pt_d_count'], dtype='object') cmr_21 (8601298, 145)\n",
      "Index(['cmr_22_count', 'cmr_22_pt_d_count'], dtype='object') cmr_22 (8601298, 147)\n",
      "Index(['cmr_23_count', 'cmr_23_pt_d_count'], dtype='object') cmr_23 (8601298, 149)\n",
      "Index(['age_count', 'age_pt_d_count'], dtype='object') age (8601298, 151)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6521.26 Mb, 3633.86 Mb (44.28 %)\n",
      "**************************task_id**************************\n",
      "**************************adv_id**************************\n",
      "**************************dev_id**************************\n",
      "**************************spread_app_id**************************\n",
      "**************************indu_name**************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1/7 [02:39<15:59, 159.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************task_id**************************\n",
      "**************************adv_id**************************\n",
      "**************************dev_id**************************\n",
      "**************************spread_app_id**************************\n",
      "**************************indu_name**************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 2/7 [05:11<13:07, 157.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************task_id**************************\n",
      "**************************adv_id**************************\n",
      "**************************dev_id**************************\n",
      "**************************spread_app_id**************************\n",
      "**************************indu_name**************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 3/7 [07:48<10:28, 157.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************task_id**************************\n",
      "**************************adv_id**************************\n",
      "**************************dev_id**************************\n",
      "**************************spread_app_id**************************\n",
      "**************************indu_name**************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 4/7 [10:41<08:06, 162.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************task_id**************************\n",
      "**************************adv_id**************************\n",
      "**************************dev_id**************************\n",
      "**************************spread_app_id**************************\n",
      "**************************indu_name**************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 5/7 [13:48<05:39, 169.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************task_id**************************\n",
      "**************************adv_id**************************\n",
      "**************************dev_id**************************\n",
      "**************************spread_app_id**************************\n",
      "**************************indu_name**************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 6/7 [17:06<02:58, 178.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************task_id**************************\n",
      "**************************adv_id**************************\n",
      "**************************dev_id**************************\n",
      "**************************spread_app_id**************************\n",
      "**************************indu_name**************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [20:30<00:00, 175.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8293.07 Mb, 5249.82 Mb (36.70 %)\n",
      "['uidtask_id_nunique', 'uidtask_id_pt_d_nunique', 'uidadv_id_nunique', 'uidadv_id_pt_d_nunique', 'uiddev_id_nunique', 'uiddev_id_pt_d_nunique', 'uidspread_app_id_nunique', 'uidspread_app_id_pt_d_nunique', 'uidindu_name_nunique', 'uidindu_name_pt_d_nunique', 'agetask_id_nunique', 'agetask_id_pt_d_nunique', 'ageadv_id_nunique', 'ageadv_id_pt_d_nunique', 'agedev_id_nunique', 'agedev_id_pt_d_nunique', 'agespread_app_id_nunique', 'agespread_app_id_pt_d_nunique', 'ageindu_name_nunique', 'ageindu_name_pt_d_nunique', 'gendertask_id_nunique', 'gendertask_id_pt_d_nunique', 'genderadv_id_nunique', 'genderadv_id_pt_d_nunique', 'genderdev_id_nunique', 'genderdev_id_pt_d_nunique', 'genderspread_app_id_nunique', 'genderspread_app_id_pt_d_nunique', 'genderindu_name_nunique', 'genderindu_name_pt_d_nunique', 'careertask_id_nunique', 'careertask_id_pt_d_nunique', 'careeradv_id_nunique', 'careeradv_id_pt_d_nunique', 'careerdev_id_nunique', 'careerdev_id_pt_d_nunique', 'careerspread_app_id_nunique', 'careerspread_app_id_pt_d_nunique', 'careerindu_name_nunique', 'careerindu_name_pt_d_nunique', 'citytask_id_nunique', 'citytask_id_pt_d_nunique', 'cityadv_id_nunique', 'cityadv_id_pt_d_nunique', 'citydev_id_nunique', 'citydev_id_pt_d_nunique', 'cityspread_app_id_nunique', 'cityspread_app_id_pt_d_nunique', 'cityindu_name_nunique', 'cityindu_name_pt_d_nunique', 'slot_idtask_id_nunique', 'slot_idtask_id_pt_d_nunique', 'slot_idadv_id_nunique', 'slot_idadv_id_pt_d_nunique', 'slot_iddev_id_nunique', 'slot_iddev_id_pt_d_nunique', 'slot_idspread_app_id_nunique', 'slot_idspread_app_id_pt_d_nunique', 'slot_idindu_name_nunique', 'slot_idindu_name_pt_d_nunique', 'net_typetask_id_nunique', 'net_typetask_id_pt_d_nunique', 'net_typeadv_id_nunique', 'net_typeadv_id_pt_d_nunique', 'net_typedev_id_nunique', 'net_typedev_id_pt_d_nunique', 'net_typespread_app_id_nunique', 'net_typespread_app_id_pt_d_nunique', 'net_typeindu_name_nunique', 'net_typeindu_name_pt_d_nunique']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [18:29<00:00, 13.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10762.12 Mb, 7973.16 Mb (25.91 %)\n",
      "drop list: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-09-17 12:20:26] - __init__.py[line:112] - INFO: Cache Successfully! File name: /home/tione/notebook/huawei/cached_data/CACHE_data_step_2_feature_0917_r5.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from base import Cache\n",
    "from tqdm import tqdm\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('precision', 5)\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "pd.set_option('max_colwidth', 200)\n",
    "pd.set_option('display.width', 5000)\n",
    "\n",
    "def reduce_mem(df, use_float16=False):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    tm_cols = df.select_dtypes('datetime').columns\n",
    "    colsuse = [i for i in df.columns if i!= 'label']\n",
    "    for col in colsuse:\n",
    "        if col in tm_cols:\n",
    "            continue\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(\n",
    "                        np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(\n",
    "                        np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(\n",
    "                        np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(\n",
    "                        np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if use_float16 and c_min > np.finfo(\n",
    "                        np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(\n",
    "                        np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('{:.2f} Mb, {:.2f} Mb ({:.2f} %)'.format(\n",
    "        start_mem, end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "print('start!')\n",
    "data = Cache.reload_cache('CACHE_dataall0816.pkl')\n",
    "print(data.dtypes)\n",
    "data['communication_onlinerate'] = data['communication_onlinerate'].map(lambda x:x.replace('^',' '))\n",
    "route = Cache.reload_cache('CACHE_cmr0816.pkl')\n",
    "route_columns = [i for i in route.columns]\n",
    "data = pd.concat([data,route],axis=1)# 无index\n",
    "data = data.reset_index(drop=True).reset_index()# 添加index\n",
    "\n",
    "cols = [i for i in data.columns if i not in ['id','index']]\n",
    "data1= data.query('pt_d<8').drop_duplicates(subset=cols)# 重复样本去掉\n",
    "data2 = data.query('pt_d==8')\n",
    "\n",
    "def get_sample(df,day,total=1500000,rate=5):\n",
    "    set1 = df.query('pt_d=={}'.format(day))# 当日数据\n",
    "    set1_pos = set1.query('label==1')\n",
    "    nums_pos = set1_pos.shape[0]\n",
    "    nums_neg = nums_pos*rate\n",
    "    set1_neg = set1.query('label==0')\n",
    "    set1_neg = set1_neg.sample(nums_neg,random_state=0)# 剩余    \n",
    "    df_sample = pd.concat([set1_pos,set1_neg])\n",
    "    print(df_sample['label'].value_counts(),df_sample['label'].mean())\n",
    "    return df_sample\n",
    "\n",
    "data1_sample = []\n",
    "for day in [1,2,3,4,5,6,7]:\n",
    "    data1_sample.append(get_sample(data1,day))\n",
    "data1_sample = pd.concat(data1_sample)\n",
    "\n",
    "data = pd.concat([data1_sample,data2],ignore_index=True)\n",
    "data = data.sort_values(['uid','pt_d','slot_id','net_type','task_id','adv_id'],ascending=False).reset_index(drop=True)\n",
    "del data1_sample,data1,data2\n",
    "gc.collect()\n",
    "\n",
    "for var in route_columns:\n",
    "    data[var] = data[var].astype(int)\n",
    "print(data.dtypes)\n",
    "del route\n",
    "gc.collect()\n",
    "\n",
    "# 修正缺失值\n",
    "sparse_features=['task_id', 'adv_id', 'creat_type_cd', 'adv_prim_id', 'dev_id', 'inter_type_cd', 'slot_id', 'spread_app_id', 'tags', 'app_first_class', 'app_second_class', 'city', 'device_name', 'career', 'gender', 'net_type', 'residence', 'emui_dev', 'indu_name', 'cmr_0', 'cmr_1', 'cmr_2', 'cmr_3', 'cmr_4', 'cmr_5', 'cmr_6', 'cmr_7', 'cmr_8', 'cmr_9', 'cmr_10', 'cmr_11', 'cmr_12', 'cmr_13', 'cmr_14', 'cmr_15', 'cmr_16', 'cmr_17', 'cmr_18', 'cmr_19', 'cmr_20', 'cmr_21', 'cmr_22', 'cmr_23', 'age', 'city_rank']\n",
    "dense_features=['his_app_size', 'his_on_shelf_time', 'app_score', 'device_size', 'list_time', 'device_price', 'up_life_duration', 'up_membership_grade', 'membership_life_duration', 'consume_purchase', 'communication_avgonline_30d', 'cmr_None']\n",
    "\n",
    "for var in sparse_features:\n",
    "    mode_num = data[var].mode()[0]\n",
    "    shape_null = data.query('{}==-1'.format(var)).shape[0]\n",
    "    print('process sparse int: ',var, 'fillna: ',mode_num, 'fillna_shape: ',shape_null)\n",
    "    if shape_null>0:\n",
    "        data.loc[data[var]==-1,var] = mode_num\n",
    "        data[var] = data[var].astype(int)\n",
    "    \n",
    "for var in dense_features:\n",
    "    mode_num = int(data[var].mean())\n",
    "    shape_null = data.query('{}==-1'.format(var)).shape[0]\n",
    "    print('process dense int: ',var, 'fillna: ',mode_num, 'fillna_shape: ',shape_null)\n",
    "    if shape_null>0:\n",
    "        data.loc[data[var]==-1,var] = mode_num\n",
    "        data[var] = data[var].astype(int)\n",
    "data = reduce_mem(data, use_float16=False)\n",
    "Cache.cache_data(data, nm_marker='data_step_1_feature_0917_r5')\n",
    "\n",
    "# ######################################################################################\n",
    "# base feature\n",
    "\n",
    "# 提取相对count特征\n",
    "## 列并行\n",
    "from multiprocessing import Pool\n",
    "\n",
    "cate_cols = ['task_id', 'adv_id', 'creat_type_cd', 'adv_prim_id', 'dev_id', 'inter_type_cd', 'slot_id', 'spread_app_id', 'tags', 'app_first_class', 'app_second_class', 'city', 'device_name', 'career', 'gender', 'net_type', 'residence', 'emui_dev', 'indu_name', 'cmr_0', 'cmr_1', 'cmr_2', 'cmr_3', 'cmr_4', 'cmr_5', 'cmr_6', 'cmr_7', 'cmr_8', 'cmr_9', 'cmr_10', 'cmr_11', 'cmr_12', 'cmr_13', 'cmr_14', 'cmr_15', 'cmr_16', 'cmr_17', 'cmr_18', 'cmr_19', 'cmr_20', 'cmr_21', 'cmr_22', 'cmr_23', 'age']\n",
    "cate_cols_df = []\n",
    "for var in tqdm(cate_cols):\n",
    "    cate_cols_df.append(data[['uid','pt_d',var]])\n",
    "\n",
    "def cls(df):\n",
    "    f = df.columns[-1]\n",
    "    mapping = dict(df.query('pt_d<8')[f].value_counts()/df.query('pt_d<8')[f].value_counts().max())# 只统计train\n",
    "    mapping_test = dict(df.query('pt_d==8')[f].value_counts()/df.query('pt_d==8')[f].value_counts().max())# 只统计test\n",
    "    for key,value in mapping_test.items():\n",
    "        # 优先用train\n",
    "        if key not in mapping:\n",
    "            mapping[key]=value\n",
    "    df[f + '_count'] = df[f].map(mapping)# 映射\n",
    "    fe = df.groupby([f,'pt_d'])['uid'].count().rename(f'{f}_pt_d_count').reset_index()# 当天统计count\n",
    "    fe_max = fe.groupby('pt_d')[f'{f}_pt_d_count'].max().rename(f'{f}_pt_d_count_max').reset_index()\n",
    "    fe = fe.merge(fe_max,on='pt_d',how='left')\n",
    "    fe[f'{f}_pt_d_count']=fe[f'{f}_pt_d_count']/fe[f'{f}_pt_d_count_max']\n",
    "    fe[f'{f}_pt_d_count']=fe[f'{f}_pt_d_count'].fillna(0)\n",
    "    del fe[f'{f}_pt_d_count_max']\n",
    "    df = df.merge(fe,on = [f,'pt_d'],how='left')\n",
    "    print(df.columns)\n",
    "    return df[[f,'pt_d',f + '_count',f'{f}_pt_d_count']]\n",
    "\n",
    "with Pool(10) as p:\n",
    "    result = p.map(cls, cate_cols_df)\n",
    "for index,fe in enumerate(result):\n",
    "    f = cate_cols[index]\n",
    "    data = pd.concat([data,fe[fe.columns[-2:]]],axis=1)\n",
    "    print(fe.columns[-2:],f,data.shape)\n",
    "    del fe\n",
    "    gc.collect()\n",
    "del result,f,cate_cols_df\n",
    "gc.collect()\n",
    "data = reduce_mem(data, use_float16=False)\n",
    "\n",
    "# target_encoding\n",
    "\n",
    "##########################groupby feature#######################\n",
    "def group_fea(data,key,target):\n",
    "    tmp = data.groupby(key, as_index=False)[target].agg({\n",
    "        key+target + '_nunique': 'nunique',\n",
    "    }).reset_index()\n",
    "    del tmp['index']\n",
    "    return tmp\n",
    "\n",
    "def group_fea_pt_d(data,key,target):\n",
    "    tmp = data.groupby([key,'pt_d'], as_index=False)[target].agg({\n",
    "        key+target + '_pt_d_nunique': 'nunique',\n",
    "    }).reset_index()\n",
    "    fe = tmp.groupby('pt_d')[ key+target + '_pt_d_nunique'].max().rename('dmax').reset_index()\n",
    "    tmp = tmp.merge(fe,on='pt_d',how='left')\n",
    "    tmp[key+target + '_pt_d_nunique']=tmp[key+target + '_pt_d_nunique']/tmp['dmax']\n",
    "    del tmp['index'],tmp['dmax']\n",
    "    print(\"**************************{}**************************\".format(target))\n",
    "    return tmp\n",
    "\n",
    "feature_key = ['uid','age','gender','career','city','slot_id','net_type']\n",
    "feature_target = ['task_id','adv_id','dev_id','spread_app_id','indu_name']\n",
    "\n",
    "for key in tqdm(feature_key):\n",
    "    for target in feature_target:\n",
    "        tmp = group_fea(data,key,target)\n",
    "        data = data.merge(tmp,on=key,how='left')\n",
    "        tmp = group_fea_pt_d(data,key,target)\n",
    "        data = data.merge(tmp,on=[key,'pt_d'],how='left')\n",
    "del tmp\n",
    "gc.collect()\n",
    "data = reduce_mem(data, use_float16=False)\n",
    "\n",
    "test_df = data[data[\"pt_d\"]==8].copy().reset_index()\n",
    "train_df = data[data[\"pt_d\"]<8].reset_index()\n",
    "del data\n",
    "gc.collect()\n",
    "\n",
    "#统计做了groupby特征的特征\n",
    "group_list = []\n",
    "for s in train_df.columns:\n",
    "    if '_nunique' in s:\n",
    "        group_list.append(s)\n",
    "print(group_list)\n",
    "\n",
    "\n",
    "##########################target_enc feature#######################\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=2020)\n",
    "enc_list = group_list + ['net_type','task_id','adv_id','adv_prim_id','age',\n",
    "                         'app_first_class','app_second_class','career','city','consume_purchase','uid','dev_id','tags','slot_id']\n",
    "for f in tqdm(enc_list):\n",
    "    train_df[f + '_target_enc'] = 0\n",
    "    test_df[f + '_target_enc'] = 0\n",
    "    for i, (trn_idx, val_idx) in enumerate(skf.split(train_df, train_df['label'])):\n",
    "        trn_x = train_df[[f, 'label']].iloc[trn_idx].reset_index(drop=True)\n",
    "        val_x = train_df[[f]].iloc[val_idx].reset_index(drop=True)\n",
    "        enc_df = trn_x.groupby(f, as_index=False)['label'].agg({f + '_target_enc': 'mean'})\n",
    "        val_x = val_x.merge(enc_df, on=f, how='left')\n",
    "        test_x = test_df[[f]].merge(enc_df, on=f, how='left')\n",
    "        val_x[f + '_target_enc'] = val_x[f + '_target_enc'].fillna(train_df['label'].mean())\n",
    "        test_x[f + '_target_enc'] = test_x[f + '_target_enc'].fillna(train_df['label'].mean())\n",
    "        train_df.loc[val_idx, f + '_target_enc'] = val_x[f + '_target_enc'].values\n",
    "        test_df[f + '_target_enc'] += test_x[f + '_target_enc'].values / skf.n_splits\n",
    "        \n",
    "del trn_x,val_x,enc_df,test_x\n",
    "gc.collect()\n",
    "# all features\n",
    "df_fe = pd.concat([train_df,test_df])\n",
    "del train_df,test_df\n",
    "df_fe = df_fe.sort_values('index').reset_index(drop=True)\n",
    "df_fe = reduce_mem(df_fe, use_float16=False)\n",
    "\n",
    "droplist = []\n",
    "set_test = df_fe.query('pt_d==8')\n",
    "for var in df_fe.columns:\n",
    "    if var not in ['id','index','label','pt_d']:\n",
    "        if set_test[var].nunique()<2 or set_test[var].count()<2:\n",
    "            droplist.append(var)\n",
    "print('drop list:',droplist)\n",
    "df_fe = df_fe.drop(droplist,axis=1)\n",
    "Cache.cache_data(df_fe , nm_marker='data_step_2_feature_0917_r5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_py3",
   "language": "python",
   "name": "conda_tensorflow2_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
