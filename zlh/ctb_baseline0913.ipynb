{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data start!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-09-13 21:02:45] - __init__.py[line:126] - INFO: Successfully Reload: /home/tione/notebook/huawei/cached_data/CACHE_data_0912.pkl\n",
      "[2020-09-13 21:03:13] - __init__.py[line:126] - INFO: Successfully Reload: /home/tione/notebook/huawei/cached_data/CACHE_data_features_0_0913.pkl\n",
      "[2020-09-13 21:04:03] - __init__.py[line:126] - INFO: Successfully Reload: /home/tione/notebook/huawei/cached_data/CACHE_datafeature0912.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36056562, 304)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from catboost import CatBoostClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import gc\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics import *\n",
    "from base import Cache\n",
    "import joblib\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('precision', 5)\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "pd.set_option('max_colwidth', 200)\n",
    "pd.set_option('display.width', 5000)\n",
    "\n",
    "def reduce_mem(df, use_float16=False):\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    tm_cols = df.select_dtypes('datetime').columns\n",
    "    for col in df.columns:\n",
    "        if col in tm_cols:\n",
    "            continue\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type).find('int') > -1:\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(\n",
    "                        np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(\n",
    "                        np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(\n",
    "                        np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(\n",
    "                        np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            elif str(col_type).find('float') > -1:\n",
    "                if use_float16 and c_min > np.finfo(\n",
    "                        np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(\n",
    "                        np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    print('{:.2f} Mb, {:.2f} Mb ({:.2f} %)'.format(\n",
    "        start_mem, end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "print('loading data start!')\n",
    "# baseindex \n",
    "dfbase = Cache.reload_cache('CACHE_data_0912.pkl')\n",
    "dfbase = dfbase[['index']]\n",
    "gc.collect()\n",
    "# step4 特征\n",
    "df_window = Cache.reload_cache('CACHE_data_step_5_0913.pkl')\n",
    "# 基础特征+编码特征\n",
    "df = Cache.reload_cache('CACHE_data_step_2_0913.pkl')\n",
    "del df['communication_onlinerate'],df['level_0']\n",
    "gc.collect()\n",
    "print(df.shape)\n",
    "df = df.merge(df_window,on='index',how='left')\n",
    "print(df.shape)\n",
    "#df = df.sort_values('index')\n",
    "fe = Cache.reload_cache('CACHE_data_step_4_features_0_0913.pkl')\n",
    "df = df.merge(fe,on='index',how='left')\n",
    "print(df.shape)\n",
    "# w2v 特征\n",
    "fe_list = ['CACHE_EMB_DICT_8_1_16_uid_task_id_w2v.pkl',\n",
    "#           'CACHE_EMB_DICT_8_1_16_uid_task_id_fasttext.pkl',\n",
    "          'CACHE_EMB_DICT_16_2_16_uid_task_id_w2v.pkl',\n",
    "#           'CACHE_EMB_DICT_16_2_16_uid_task_id_fasttext.pkl',\n",
    "          'CACHE_EMB_DICT_8_1_16_uid_adv_id_w2v.pkl',\n",
    "#           'CACHE_EMB_DICT_8_1_16_uid_adv_id_fasttext.pkl',\n",
    "          'CACHE_EMB_DICT_16_2_16_uid_adv_id_w2v.pkl',\n",
    "#           'CACHE_EMB_DICT_16_2_16_uid_adv_id_fasttext.pkl',\n",
    "          'CACHE_EMB_DICT_8_1_4_uid_creat_type_cd_w2v.pkl',\n",
    "          'CACHE_EMB_DICT_8_1_8_uid_communication_onlinerate_w2v.pkl',\n",
    "           'CACHE_EMB_DICT_8_1_8_uid_slot_id_w2v.pkl'\n",
    "          ]\n",
    "for var in fe_list:\n",
    "    fe = Cache.reload_cache(var)\n",
    "    if isinstance(fe,dict):\n",
    "        fe = fe['sentence_emb_df']\n",
    "    if 'index' in fe.columns:\n",
    "        df = df.merge(fe,on='index',how='left')\n",
    "        print('join')\n",
    "    else:\n",
    "        fe = pd.concat([dfbase,fe],axis=1)# 加上，index\n",
    "        df = df.merge(fe,on='index',how='left')\n",
    "        print('concat')\n",
    "    print(df.shape)\n",
    "print(df.dtypes)\n",
    "df['label'] = df['label'].fillna(-1).astype(int)\n",
    "df = reduce_mem(df, use_float16=True)\n",
    "print('loading data finish!')\n",
    "\n",
    "\n",
    "#线下数据集的切分\n",
    "X_train = df[df[\"pt_d\"]<7].copy()\n",
    "y_train = X_train[\"label\"].astype('int32')\n",
    "X_valid = df[df[\"pt_d\"]==7]\n",
    "y_valid = X_valid[\"label\"].astype('int32')\n",
    "test_df = df[df[\"pt_d\"]==8].copy()\n",
    "#筛选特征\n",
    "drop_fea = ['pt_d','label','communication_onlinerate','index']\n",
    "feature= [x for x in X_train.columns if x not in drop_fea]\n",
    "print(len(feature))\n",
    "print(feature)\n",
    "\n",
    "#线下验证\n",
    "cate_fea = []\n",
    "clf = CatBoostClassifier(iterations=10000, depth=6,learning_rate=0.1, loss_function='Logloss',cat_features=cate_fea,thread_count=50\n",
    "                        ,verbose=True,eval_metric='AUC',counter_calc_method='Full',metric_period=1000)\n",
    "clf.fit(\n",
    "    X_train[feature], y_train.astype('int32'),\n",
    "    eval_set=[(X_valid[feature],y_valid.astype('int32'))],\n",
    "    early_stopping_rounds=200,\n",
    "    verbose=True,\n",
    "    use_best_model=True,\n",
    ")\n",
    "joblib.dump(clf,'./models/ctb_local0913.pkl')\n",
    "y_predprob = clf.predict_proba(X_valid[feature])[:, 1] \n",
    "\n",
    "y_pre = clf.predict_proba(test_df[feature])[:, 1]  \n",
    "auc_score =roc_auc_score(y_valid, y_predprob)\n",
    "print(\"AUC Score (Valid): %f\" % auc_score)\n",
    "\n",
    "#查看模型的特征重要性\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib import cm\n",
    "score = pd.DataFrame()\n",
    "score['fea_name'] = clf.feature_names_\n",
    "score['fea']=clf.feature_importances_\n",
    "score = score.sort_values(['fea'], ascending=False)\n",
    "temp = pd.DataFrame()\n",
    "temp = score[:100]\n",
    "color = cm.jet(temp['fea']/temp['fea'].max())\n",
    "plt.figure(figsize=(10, 15))\n",
    "plt.barh(temp['fea_name'],temp['fea'],height =0.8,color=color,alpha=0.8)\n",
    "plt.show()\n",
    "\n",
    "# 线上提交的模型训练\n",
    "clf1 = CatBoostClassifier(iterations=clf.best_iteration_, depth=6,learning_rate=0.1, loss_function='Logloss',thread_count=50\n",
    "                        ,eval_metric='AUC',counter_calc_method='Full',task_type='GPU',metric_period=50)\n",
    "clf1.fit(\n",
    "    df[df[\"pt_d\"]<=7][feature], df[df[\"pt_d\"]<=7]['label'].astype('int32'),\n",
    "    verbose=True,\n",
    "    use_best_model=True,\n",
    ")\n",
    "joblib.dump(clf1,'./models/ctb_local0913pkl')\n",
    "y_pre = clf1.predict_proba(test_df[feature])[:, 1]    \n",
    "\n",
    "res = pd.DataFrame()\n",
    "res['id'] = test_df['id'].astype('int32')\n",
    "res['probability'] = y_pre\n",
    "res.to_csv('./subs/ctb_0913_{}.csv'.format(auc_score),index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_py3",
   "language": "python",
   "name": "conda_tensorflow_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}