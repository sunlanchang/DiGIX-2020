{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-09-12 17:43:40] - __init__.py[line:126] - INFO: Successfully Reload: /home/tione/notebook/huawei/cached_data/CACHE_dataall0816.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label                          float64\n",
      "uid                              int32\n",
      "task_id                          int16\n",
      "adv_id                           int16\n",
      "creat_type_cd                     int8\n",
      "adv_prim_id                      int16\n",
      "dev_id                            int8\n",
      "inter_type_cd                     int8\n",
      "slot_id                           int8\n",
      "spread_app_id                     int8\n",
      "tags                              int8\n",
      "app_first_class                   int8\n",
      "app_second_class                  int8\n",
      "age                               int8\n",
      "city                             int16\n",
      "city_rank                         int8\n",
      "device_name                       int8\n",
      "device_size                      int16\n",
      "career                            int8\n",
      "gender                            int8\n",
      "net_type                          int8\n",
      "residence                         int8\n",
      "his_app_size                      int8\n",
      "his_on_shelf_time                 int8\n",
      "app_score                         int8\n",
      "emui_dev                          int8\n",
      "list_time                         int8\n",
      "device_price                      int8\n",
      "up_life_duration                  int8\n",
      "up_membership_grade               int8\n",
      "membership_life_duration          int8\n",
      "consume_purchase                  int8\n",
      "communication_onlinerate        object\n",
      "communication_avgonline_30d       int8\n",
      "indu_name                         int8\n",
      "pt_d                              int8\n",
      "id                               int32\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-09-12 17:44:04] - __init__.py[line:126] - INFO: Successfully Reload: /home/tione/notebook/huawei/cached_data/CACHE_cmr0816.pkl\n",
      "[2020-09-12 17:50:43] - utils.py[line:126] - INFO: Note: detected 80 virtual cores but NumExpr set to maximum of 64, check \"NUMEXPR_MAX_THREADS\" environment variable.\n",
      "[2020-09-12 17:50:43] - utils.py[line:129] - INFO: Note: NumExpr detected 80 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "[2020-09-12 17:50:43] - utils.py[line:141] - INFO: NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index               int64\n",
      "label             float64\n",
      "uid                 int32\n",
      "task_id             int16\n",
      "adv_id              int16\n",
      "                   ...   \n",
      "cmr_21              int64\n",
      "cmr_22              int64\n",
      "cmr_23              int64\n",
      "cmr_None            int64\n",
      "sample_nunique    float64\n",
      "Length: 64, dtype: object\n",
      "process sparse int:  task_id fillna:  3869 fillna_shape:  0\n",
      "process sparse int:  adv_id fillna:  6751 fillna_shape:  0\n",
      "process sparse int:  creat_type_cd fillna:  7 fillna_shape:  0\n",
      "process sparse int:  adv_prim_id fillna:  207 fillna_shape:  0\n",
      "process sparse int:  dev_id fillna:  60 fillna_shape:  0\n",
      "process sparse int:  inter_type_cd fillna:  5 fillna_shape:  0\n",
      "process sparse int:  slot_id fillna:  12 fillna_shape:  0\n",
      "process sparse int:  spread_app_id fillna:  13 fillna_shape:  0\n",
      "process sparse int:  tags fillna:  37 fillna_shape:  0\n",
      "process sparse int:  app_first_class fillna:  4 fillna_shape:  0\n",
      "process sparse int:  app_second_class fillna:  21 fillna_shape:  0\n",
      "process sparse int:  city fillna:  207 fillna_shape:  0\n",
      "process sparse int:  device_name fillna:  56 fillna_shape:  0\n",
      "process sparse int:  career fillna:  4 fillna_shape:  0\n",
      "process sparse int:  gender fillna:  2 fillna_shape:  0\n",
      "process sparse int:  net_type fillna:  2 fillna_shape:  0\n",
      "process sparse int:  residence fillna:  20 fillna_shape:  0\n",
      "process sparse int:  emui_dev fillna:  20 fillna_shape:  0\n",
      "process sparse int:  indu_name fillna:  17 fillna_shape:  0\n",
      "process sparse int:  cmr_0 fillna:  0 fillna_shape:  0\n",
      "process sparse int:  cmr_1 fillna:  0 fillna_shape:  0\n",
      "process sparse int:  cmr_2 fillna:  0 fillna_shape:  0\n",
      "process sparse int:  cmr_3 fillna:  0 fillna_shape:  0\n",
      "process sparse int:  cmr_4 fillna:  1 fillna_shape:  0\n",
      "process sparse int:  cmr_5 fillna:  1 fillna_shape:  0\n",
      "process sparse int:  cmr_6 fillna:  1 fillna_shape:  0\n",
      "process sparse int:  cmr_7 fillna:  1 fillna_shape:  0\n",
      "process sparse int:  cmr_8 fillna:  1 fillna_shape:  0\n",
      "process sparse int:  cmr_9 fillna:  1 fillna_shape:  0\n",
      "process sparse int:  cmr_10 fillna:  1 fillna_shape:  0\n",
      "process sparse int:  cmr_11 fillna:  1 fillna_shape:  0\n",
      "process sparse int:  cmr_12 fillna:  1 fillna_shape:  0\n",
      "process sparse int:  cmr_13 fillna:  1 fillna_shape:  0\n",
      "process sparse int:  cmr_14 fillna:  1 fillna_shape:  0\n",
      "process sparse int:  cmr_15 fillna:  1 fillna_shape:  0\n",
      "process sparse int:  cmr_16 fillna:  1 fillna_shape:  0\n",
      "process sparse int:  cmr_17 fillna:  1 fillna_shape:  0\n",
      "process sparse int:  cmr_18 fillna:  1 fillna_shape:  0\n",
      "process sparse int:  cmr_19 fillna:  1 fillna_shape:  0\n",
      "process sparse int:  cmr_20 fillna:  1 fillna_shape:  0\n",
      "process sparse int:  cmr_21 fillna:  1 fillna_shape:  0\n",
      "process sparse int:  cmr_22 fillna:  1 fillna_shape:  0\n",
      "process sparse int:  cmr_23 fillna:  1 fillna_shape:  0\n",
      "process sparse int:  age fillna:  5 fillna_shape:  101276\n",
      "process sparse int:  city_rank fillna:  3 fillna_shape:  0\n",
      "process dense int:  his_app_size fillna:  6 fillna_shape:  8080100\n",
      "process dense int:  his_on_shelf_time fillna:  1 fillna_shape:  8080100\n",
      "process dense int:  app_score fillna:  1 fillna_shape:  0\n",
      "process dense int:  device_size fillna:  158 fillna_shape:  0\n",
      "process dense int:  list_time fillna:  9 fillna_shape:  101276\n",
      "process dense int:  device_price fillna:  3 fillna_shape:  101276\n",
      "process dense int:  up_life_duration fillna:  12 fillna_shape:  10312906\n",
      "process dense int:  up_membership_grade fillna:  0 fillna_shape:  31641917\n",
      "process dense int:  membership_life_duration fillna:  0 fillna_shape:  36000003\n",
      "process dense int:  consume_purchase fillna:  2 fillna_shape:  0\n",
      "process dense int:  communication_avgonline_30d fillna:  11 fillna_shape:  119446\n",
      "process dense int:  cmr_None fillna:  3 fillna_shape:  0\n",
      "process dense int:  sample_nunique fillna:  0 fillna_shape:  0\n",
      "11725.70 Mb, 3266.69 Mb (72.14 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-09-12 18:05:46] - __init__.py[line:111] - INFO: Cache Successfully! File name: /home/tione/notebook/huawei/cached_data/CACHE_data_0912.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from base import Cache\n",
    "from tqdm import tqdm\n",
    "\n",
    "def reduce_mem(df, use_float16=False):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    tm_cols = df.select_dtypes('datetime').columns\n",
    "    colsuse = [i for i in df.columns if i!= 'label']\n",
    "    for col in colsuse:\n",
    "        if col in tm_cols:\n",
    "            continue\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(\n",
    "                        np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(\n",
    "                        np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(\n",
    "                        np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(\n",
    "                        np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if use_float16 and c_min > np.finfo(\n",
    "                        np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(\n",
    "                        np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('{:.2f} Mb, {:.2f} Mb ({:.2f} %)'.format(\n",
    "        start_mem, end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "data = Cache.reload_cache('CACHE_dataall0816.pkl')\n",
    "print(data.dtypes)\n",
    "data['communication_onlinerate'] = data['communication_onlinerate'].map(lambda x:x.replace('^',' '))\n",
    "route = Cache.reload_cache('CACHE_cmr0816.pkl')\n",
    "route_columns = [i for i in route.columns]\n",
    "data = pd.concat([data,route],axis=1)# 无index\n",
    "data = data.reset_index(drop=True).reset_index()\n",
    "# 计算每个样本当日重复几次\n",
    "cols = [i for i in data.columns if i not in ['index','id']]\n",
    "fe = data.groupby(cols)['index'].count().rename('sample_nunique').reset_index()\n",
    "fe_max = fe.groupby('pt_d')['sample_nunique'].max().rename('sample_nunique_max').reset_index()\n",
    "fe = fe.merge(fe_max,on='pt_d',how='left')\n",
    "fe['sample_nunique'] = fe['sample_nunique']/fe['sample_nunique_max']\n",
    "del fe['sample_nunique_max']\n",
    "data = data.merge(fe,on=cols,how='left')# 保留相对值\n",
    "gc.collect()\n",
    "\n",
    "data1= data.query('pt_d<8').drop_duplicates(subset=cols)# 重复样本去掉\n",
    "data2 = data.query('pt_d==8')\n",
    "data = pd.concat([data1,data2],ignore_index=True)\n",
    "data = data.sort_values(['uid','pt_d','slot_id','net_type','task_id','adv_id'],ascending=False).reset_index(drop=True)\n",
    "del data1,data2\n",
    "gc.collect()\n",
    "\n",
    "for var in route_columns:\n",
    "    data[var] = data[var].astype(int)\n",
    "print(data.dtypes)\n",
    "del route\n",
    "gc.collect()\n",
    "\n",
    "# 修正缺失值\n",
    "sparse_features=['task_id', 'adv_id', 'creat_type_cd', 'adv_prim_id', 'dev_id', 'inter_type_cd', 'slot_id', 'spread_app_id', 'tags', 'app_first_class', 'app_second_class', 'city', 'device_name', 'career', 'gender', 'net_type', 'residence', 'emui_dev', 'indu_name', 'cmr_0', 'cmr_1', 'cmr_2', 'cmr_3', 'cmr_4', 'cmr_5', 'cmr_6', 'cmr_7', 'cmr_8', 'cmr_9', 'cmr_10', 'cmr_11', 'cmr_12', 'cmr_13', 'cmr_14', 'cmr_15', 'cmr_16', 'cmr_17', 'cmr_18', 'cmr_19', 'cmr_20', 'cmr_21', 'cmr_22', 'cmr_23', 'age', 'city_rank']\n",
    "dense_features=['his_app_size', 'his_on_shelf_time', 'app_score', 'device_size', 'list_time', 'device_price', 'up_life_duration', 'up_membership_grade', 'membership_life_duration', 'consume_purchase', 'communication_avgonline_30d', 'cmr_None','sample_nunique']\n",
    "\n",
    "for var in sparse_features:\n",
    "    mode_num = data[var].mode()[0]\n",
    "    shape_null = data.query('{}==-1'.format(var)).shape[0]\n",
    "    print('process sparse int: ',var, 'fillna: ',mode_num, 'fillna_shape: ',shape_null)\n",
    "    if shape_null>0:\n",
    "        data.loc[data[var]==-1,var] = mode_num\n",
    "        data[var] = data[var].astype(int)\n",
    "    \n",
    "for var in dense_features:\n",
    "    mode_num = int(data[var].mean())\n",
    "    shape_null = data.query('{}==-1'.format(var)).shape[0]\n",
    "    print('process dense int: ',var, 'fillna: ',mode_num, 'fillna_shape: ',shape_null)\n",
    "    if shape_null>0:\n",
    "        data.loc[data[var]==-1,var] = mode_num\n",
    "        data[var] = data[var].astype(int)\n",
    "data = reduce_mem(data, use_float16=False)\n",
    "Cache.cache_data(data, nm_marker='data_0912')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-09-12 19:05:50] - __init__.py[line:126] - INFO: Successfully Reload: /home/tione/notebook/huawei/cached_data/CACHE_data_0912.pkl\n",
      "100%|██████████| 44/44 [00:10<00:00,  4.10it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from base import Cache\n",
    "from tqdm import tqdm\n",
    "\n",
    "def reduce_mem(df, use_float16=False):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    tm_cols = df.select_dtypes('datetime').columns\n",
    "    colsuse = [i for i in df.columns if i!= 'label']\n",
    "    for col in colsuse:\n",
    "        if col in tm_cols:\n",
    "            continue\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(\n",
    "                        np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(\n",
    "                        np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(\n",
    "                        np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(\n",
    "                        np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if use_float16 and c_min > np.finfo(\n",
    "                        np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(\n",
    "                        np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('{:.2f} Mb, {:.2f} Mb ({:.2f} %)'.format(\n",
    "        start_mem, end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "data = Cache.reload_cache('CACHE_data_0912.pkl')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('precision', 5)\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "pd.set_option('max_colwidth', 200)\n",
    "pd.set_option('display.width', 5000)\n",
    "# 提取相对count特征\n",
    "## 列并行\n",
    "from multiprocessing import Pool\n",
    "\n",
    "cate_cols = ['task_id', 'adv_id', 'creat_type_cd', 'adv_prim_id', 'dev_id', 'inter_type_cd', 'slot_id', 'spread_app_id', 'tags', 'app_first_class', 'app_second_class', 'city', 'device_name', 'career', 'gender', 'net_type', 'residence', 'emui_dev', 'indu_name', 'cmr_0', 'cmr_1', 'cmr_2', 'cmr_3', 'cmr_4', 'cmr_5', 'cmr_6', 'cmr_7', 'cmr_8', 'cmr_9', 'cmr_10', 'cmr_11', 'cmr_12', 'cmr_13', 'cmr_14', 'cmr_15', 'cmr_16', 'cmr_17', 'cmr_18', 'cmr_19', 'cmr_20', 'cmr_21', 'cmr_22', 'cmr_23', 'age']\n",
    "cate_cols_df = []\n",
    "for var in tqdm(cate_cols):\n",
    "    cate_cols_df.append(data[['uid','pt_d',var]])\n",
    "\n",
    "def cls(df):\n",
    "    f = df.columns[-1]\n",
    "    df[f + '_count_trn'] = df[f].map(df.query('pt_d<8')[f].value_counts())# 只统计train\n",
    "    df[f + '_count_trn'] = df[f + '_count_trn']/df[f + '_count_trn'].max()# train里相对是多少count\n",
    "    df[f + '_count_tst'] = df[f].map(df.query('pt_d==8')[f].value_counts())# 映射\n",
    "    df[f + '_count_tst'] = df[f + '_count_tst']/df.query('pt_d<8')[f + '_count_tst'].max()# test管test统计\n",
    "    df[f + '_count'] = df.apply(lambda x:x[f + '_count_trn'] if x['pt_d']<8 else x[f + '_count_tst'],axis=1)# train ，test分别统计的count\n",
    "    del df[f + '_count_trn'], df[f + '_count_tst']\n",
    "    fe = df.groupby([f,'pt_d'])['uid'].count().rename(f'{f}_pt_d_count').reset_index()# 当天统计count\n",
    "    fe_max = fe.groupby('pt_d')[f'{f}_pt_d_count'].max().rename(f'{f}_pt_d_count_max').reset_index()\n",
    "    fe = fe.merge(fe_max,on='pt_d',how='left')\n",
    "    fe[f'{f}_pt_d_count']=fe[f'{f}_pt_d_count']/fe[f'{f}_pt_d_count_max']\n",
    "    fe[f'{f}_pt_d_count']=fe[f'{f}_pt_d_count'].fillna(0)\n",
    "    del fe[f'{f}_pt_d_count_max']\n",
    "    df = df.merge(fe,on = [f,'pt_d'],how='left')\n",
    "    print(df.columns)\n",
    "    return df[[f,'pt_d',f + '_count',f'{f}_pt_d_count']]\n",
    "\n",
    "with Pool(14) as p:\n",
    "    result = p.map(cls, cate_cols_df)\n",
    "for index,fe in enumerate(result):\n",
    "    f = cate_cols[index]\n",
    "    data = pd.concat([data,fe[fe.columns[-2:]]],axis=1)\n",
    "    print(fe.columns[-2:],f)\n",
    "del result,f,fe,cate_cols_df\n",
    "gc.collect()\n",
    "##########################groupby feature#######################\n",
    "def group_fea(data,key,target):\n",
    "    tmp = data.groupby(key, as_index=False)[target].agg({\n",
    "        key+target + '_nunique': 'nunique',\n",
    "    }).reset_index()\n",
    "    del tmp['index']\n",
    "    return tmp\n",
    "\n",
    "def group_fea_pt_d(data,key,target):\n",
    "    tmp = data.groupby([key,'pt_d'], as_index=False)[target].agg({\n",
    "        key+target + '_pt_d_nunique': 'nunique',\n",
    "    }).reset_index()\n",
    "    fe = tmp.groupby('pt_d')[ key+target + '_pt_d_nunique'].max().rename('dmax').reset_index()\n",
    "    tmp = tmp.merge(fe,on='pt_d',how='left')\n",
    "    tmp[key+target + '_pt_d_nunique']=tmp[key+target + '_pt_d_nunique']/tmp['dmax']\n",
    "    del tmp['index'],tmp['dmax']\n",
    "    print(\"**************************{}**************************\".format(target))\n",
    "    return tmp\n",
    "\n",
    "feature_key = ['uid','age','gender','career','city','slot_id','net_type']\n",
    "feature_target = ['task_id','adv_id','dev_id','spread_app_id','indu_name']\n",
    "\n",
    "for key in tqdm(feature_key):\n",
    "    for target in feature_target:\n",
    "        tmp = group_fea(data,key,target)\n",
    "        data = data.merge(tmp,on=key,how='left')\n",
    "        tmp = group_fea_pt_d(data,key,target)\n",
    "        data = data.merge(tmp,on=key,how='left')\n",
    "del tmp\n",
    "gc.collect()\n",
    "data = reduce_mem(data, use_float16=False)\n",
    "\n",
    "test_df = data[data[\"pt_d\"]==8].copy().reset_index()\n",
    "train_df = data[data[\"pt_d\"]<8].reset_index()\n",
    "del data\n",
    "gc.collect()\n",
    "\n",
    "#统计做了groupby特征的特征\n",
    "group_list = []\n",
    "for s in train_df.columns:\n",
    "    if '_nunique' in s:\n",
    "        group_list.append(s)\n",
    "print(group_list)\n",
    "\n",
    "\n",
    "##########################target_enc feature#######################\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=2020)\n",
    "enc_list = group_list + ['net_type','task_id','adv_id','adv_prim_id','age','app_first_class','app_second_class','career','city','consume_purchase','uid','uid_count','dev_id','tags','slot_id']\n",
    "for f in tqdm(enc_list):\n",
    "    train_df[f + '_target_enc'] = 0\n",
    "    test_df[f + '_target_enc'] = 0\n",
    "    for i, (trn_idx, val_idx) in enumerate(skf.split(train_df, train_df['label'])):\n",
    "        trn_x = train_df[[f, 'label']].iloc[trn_idx].reset_index(drop=True)\n",
    "        val_x = train_df[[f]].iloc[val_idx].reset_index(drop=True)\n",
    "        enc_df = trn_x.groupby(f, as_index=False)['label'].agg({f + '_target_enc': 'mean'})\n",
    "        val_x = val_x.merge(enc_df, on=f, how='left')\n",
    "        test_x = test_df[[f]].merge(enc_df, on=f, how='left')\n",
    "        val_x[f + '_target_enc'] = val_x[f + '_target_enc'].fillna(train_df['label'].mean())\n",
    "        test_x[f + '_target_enc'] = test_x[f + '_target_enc'].fillna(train_df['label'].mean())\n",
    "        train_df.loc[val_idx, f + '_target_enc'] = val_x[f + '_target_enc'].values\n",
    "        test_df[f + '_target_enc'] += test_x[f + '_target_enc'].values / skf.n_splits\n",
    "        \n",
    "del trn_x,val_x,enc_df,test_x\n",
    "gc.collect()\n",
    "# all features\n",
    "df_fe = pd.concat([train_df,test_df])\n",
    "del train_df,test_df\n",
    "df_fe = df_fe.sort_values('index').reset_index(drop=True)\n",
    "df_fe = reduce_mem(df_fe, use_float16=False)\n",
    "droplist = []\n",
    "set_test = df_fe.query('pt_d==8')\n",
    "for var in df_fe.columns:\n",
    "    if var not in ['id','index','label','pt_d']:\n",
    "        if set_test[var].nunique()<2 or set_test[var].count()<2:\n",
    "            droplist.append(var)\n",
    "print('drop list:',droplist)\n",
    "df_fe = df_fe.drop(droplist,axis=1)\n",
    "Cache.cache_data(df_fe , nm_marker='datafeature0912')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_py3",
   "language": "python",
   "name": "conda_tensorflow2_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
