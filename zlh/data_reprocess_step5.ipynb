{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-09-13 17:23:10] - __init__.py[line:126] - INFO: Successfully Reload: /home/tione/notebook/huawei/cached_data/CACHE_data_0912.pkl\n"
     ]
    }
   ],
   "source": [
    "# uid 当天特征\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from base import Cache\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('precision', 5)\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "pd.set_option('max_colwidth', 200)\n",
    "pd.set_option('display.width', 5000)\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def reduce_mem(df, use_float16=False):\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    tm_cols = df.select_dtypes('datetime').columns\n",
    "    for col in df.columns:\n",
    "        if col in tm_cols:\n",
    "            continue\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type).find('int') > -1:\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(\n",
    "                        np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(\n",
    "                        np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(\n",
    "                        np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(\n",
    "                        np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            elif str(col_type).find('float') > -1:\n",
    "                if use_float16 and c_min > np.finfo(\n",
    "                        np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(\n",
    "                        np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    print('{:.2f} Mb, {:.2f} Mb ({:.2f} %)'.format(\n",
    "        start_mem, end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "\n",
    "data = Cache.reload_cache('CACHE_data_0912.pkl')\n",
    "\n",
    "# 当天count的rank已经做了编码，这里统计当天这个用户 点击某个类占曝光的比例\n",
    "cate_fe = ['task_id','creat_type_cd','adv_id','adv_prim_id','dev_id',\n",
    "                                  'inter_type_cd','spread_app_id','tags','app_first_class',\n",
    "                                  'app_second_class','indu_name','slot_id','net_type']\n",
    "add_cols = []\n",
    "count_fe = data.groupby(['uid','pt_d'])['index'].count().rename('uid_pt_d_total_counts').reset_index()# 当日曝光数量\n",
    "count_fe_max = count_fe.groupby(['pt_d'])['uid_pt_d_total_counts'].max().rename('uid_pt_d_total_counts_max').reset_index()# 当日曝光数量max\n",
    "data = data.merge(count_fe,on=['uid','pt_d'],how='left')\n",
    "data = data.merge(count_fe_max,on=['pt_d'],how='left')\n",
    "add_cols.append('uid_pt_d_total_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "map_rate = data['uid_pt_d_total_counts'].values/data['uid_pt_d_total_counts_max'].values\n",
    "print(map_rate.shape)\n",
    "for var in tqdm(cate_fe):\n",
    "    fe = data.groupby(['uid','pt_d',var])['index'].count().rename(f'uid_pt_d_{var}_counts').reset_index()# 当日点击这个item的数量\n",
    "    fe_max = fe.groupby(['uid','pt_d'])[f'uid_pt_d_{var}_counts'].max().rename(f'uid_pt_d_{var}_counts_max').reset_index()# 最大值\n",
    "    fe = fe.merge(fe_max,on=['uid','pt_d'],how='left')\n",
    "    # 平滑的曝光占比\n",
    "    data = data.merge(fe,on=['uid','pt_d',var],how='left')\n",
    "    print(data.shape)\n",
    "    data[f'uid_pt_d_{var}_sm_curr_rate'] = (data[f'uid_pt_d_{var}_counts'].values+2.0)/(data['uid_pt_d_total_counts'].values+3.0)\n",
    "    data[f'uid_pt_d_{var}_counts'] = (data[f'uid_pt_d_{var}_counts'].values+1.0)/(data[f'uid_pt_d_{var}_counts_max'].values+1.0)# 平滑\n",
    "    data[f'uid_pt_d_{var}_rank_sm_curr_rate'] = (data[f'uid_pt_d_{var}_counts'].values)/map_rate\n",
    "    del data[f'uid_pt_d_{var}_counts_max']\n",
    "    gc.collect()\n",
    "    add_cols.append(f'uid_pt_d_{var}_sm_curr_rate')\n",
    "    add_cols.append(f'uid_pt_d_{var}_rank_sm_curr_rate')\n",
    "    add_cols.append(f'uid_pt_d_{var}_counts')\n",
    "    print(data.shape)\n",
    "fe = data.groupby(['uid','pt_d','slot_id','net_type'])['index'].count().rename(f'uid_pt_d_slot_id_net_type_counts').reset_index()# 当日点击这个item的数量\n",
    "fe_max = fe.groupby(['uid','pt_d'])[f'uid_pt_d_slot_id_net_type_counts'].max().rename(f'uid_pt_d_slot_id_net_type_counts_max').reset_index()# 最大值\n",
    "fe = fe.merge(fe_max,on=['uid','pt_d'],how='left')\n",
    "data = data.merge(fe,on=['uid','pt_d','slot_id','net_type'],how='left')\n",
    "data[f'uid_pt_d_slot_id_net_type_sm_curr_rate'] = (data[f'uid_pt_d_slot_id_net_type_counts'].values+2.0)/(data['uid_pt_d_total_counts'].values+3.0)\n",
    "data[f'uid_pt_d_slot_id_net_type_counts'] = (data[f'uid_pt_d_slot_id_net_type_counts'].values+1.0)/(data[f'uid_pt_d_slot_id_net_type_counts_max'].values+1.0)# 平滑\n",
    "data[f'uid_pt_d_slot_id_net_type_rank_sm_curr_rate'] = (data[f'uid_pt_d_slot_id_net_type_counts'].values)/map_rate\n",
    "del data[f'uid_pt_d_slot_id_net_type_counts_max']\n",
    "add_cols.append(f'uid_pt_d_slot_id_net_type_sm_curr_rate')\n",
    "add_cols.append(f'uid_pt_d_slot_id_net_type_rank_sm_curr_rate')\n",
    "add_cols.append(f'uid_pt_d_slot_id_net_type_counts')\n",
    "\n",
    "data['uid_pt_d_total_counts'] = data['uid_pt_d_total_counts']/data['uid_pt_d_total_counts_max']# 补上，做成相对值\n",
    "del data['uid_pt_d_total_counts_max']\n",
    "dara = data[['index']+add_cols]\n",
    "gc.collect()\n",
    "data = reduce_mem(data, use_float16=False)\n",
    "Cache.cache_data(data, nm_marker='data_step_5_0913')# 有index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_py3",
   "language": "python",
   "name": "conda_tensorflow_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}