{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data start!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-09-17 13:00:22] - __init__.py[line:127] - INFO: Successfully Reload: /home/tione/notebook/huawei/cached_data/CACHE_data_step_2_feature_0917_r5.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8601298, 304)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-09-17 13:00:25] - __init__.py[line:127] - INFO: Successfully Reload: /home/tione/notebook/huawei/cached_data/CACHE_data_step_3_features_0_0917_r5.pkl\n",
      "[2020-09-17 13:00:29] - __init__.py[line:127] - INFO: Successfully Reload: /home/tione/notebook/huawei/cached_data/CACHE_data_step_3_features_1_0917_r5.pkl\n",
      "[2020-09-17 13:00:32] - __init__.py[line:127] - INFO: Successfully Reload: /home/tione/notebook/huawei/cached_data/CACHE_data_step_3_features_2_0917_r5.pkl\n",
      "[2020-09-17 13:00:36] - __init__.py[line:127] - INFO: Successfully Reload: /home/tione/notebook/huawei/cached_data/CACHE_data_step_4_feature_0917_r5.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from catboost import CatBoostClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import gc\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics import *\n",
    "from base import Cache\n",
    "import joblib\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('precision', 5)\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "pd.set_option('max_colwidth', 200)\n",
    "pd.set_option('display.width', 5000)\n",
    "\n",
    "def reduce_mem(df, use_float16=False):\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    tm_cols = df.select_dtypes('datetime').columns\n",
    "    for col in df.columns:\n",
    "        if col in tm_cols:\n",
    "            continue\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type).find('int') > -1:\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(\n",
    "                        np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(\n",
    "                        np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(\n",
    "                        np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(\n",
    "                        np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            elif str(col_type).find('float') > -1:\n",
    "                if use_float16 and c_min > np.finfo(\n",
    "                        np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(\n",
    "                        np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    print('{:.2f} Mb, {:.2f} Mb ({:.2f} %)'.format(\n",
    "        start_mem, end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "print('loading data start!')\n",
    "gc.collect()\n",
    "# step2 基础特征+编码特征\n",
    "df = Cache.reload_cache('CACHE_data_step_2_feature_0917_r5.pkl')\n",
    "del df['communication_onlinerate'],df['level_0']\n",
    "gc.collect()\n",
    "print(df.shape)\n",
    "\n",
    "# step3 特征\n",
    "df_window0 = Cache.reload_cache('CACHE_data_step_3_features_0_0917_r5.pkl')\n",
    "df_window1 = Cache.reload_cache('CACHE_data_step_3_features_1_0917_r5.pkl')\n",
    "df_window2 = Cache.reload_cache('CACHE_data_step_3_features_2_0917_r5.pkl')\n",
    "\n",
    "# # step4 uid 特征\n",
    "# df_uid = Cache.reload_cache('CACHE_data_step_4_feature_0917_r5.pkl')\n",
    "# df_uid = df_uid[['index','uid_pt_d_total_counts',\n",
    "#  'uid_pt_d_task_id_counts',\n",
    "#  'uid_pt_d_task_id_sm_curr_rate',\n",
    "#  'uid_pt_d_task_id_rank_sm_curr_rate',\n",
    "#  'uid_pt_d_creat_type_cd_counts',\n",
    "#  'uid_pt_d_creat_type_cd_sm_curr_rate',\n",
    "#  'uid_pt_d_creat_type_cd_rank_sm_curr_rate',\n",
    "#  'uid_pt_d_adv_id_counts',\n",
    "#  'uid_pt_d_adv_id_sm_curr_rate',\n",
    "#  'uid_pt_d_adv_id_rank_sm_curr_rate',\n",
    "#  'uid_pt_d_adv_prim_id_counts',\n",
    "#  'uid_pt_d_adv_prim_id_sm_curr_rate',\n",
    "#  'uid_pt_d_adv_prim_id_rank_sm_curr_rate',\n",
    "#  'uid_pt_d_dev_id_counts',\n",
    "#  'uid_pt_d_dev_id_sm_curr_rate',\n",
    "#  'uid_pt_d_dev_id_rank_sm_curr_rate',\n",
    "#  'uid_pt_d_inter_type_cd_counts',\n",
    "#  'uid_pt_d_inter_type_cd_sm_curr_rate',\n",
    "#  'uid_pt_d_inter_type_cd_rank_sm_curr_rate',\n",
    "#  'uid_pt_d_spread_app_id_counts',\n",
    "#  'uid_pt_d_spread_app_id_sm_curr_rate',\n",
    "#  'uid_pt_d_spread_app_id_rank_sm_curr_rate',\n",
    "#  'uid_pt_d_tags_counts',\n",
    "#  'uid_pt_d_tags_sm_curr_rate',\n",
    "#  'uid_pt_d_tags_rank_sm_curr_rate',\n",
    "#  'uid_pt_d_app_first_class_counts',\n",
    "#  'uid_pt_d_app_first_class_sm_curr_rate',\n",
    "#  'uid_pt_d_app_first_class_rank_sm_curr_rate',\n",
    "#  'uid_pt_d_app_second_class_counts',\n",
    "#  'uid_pt_d_app_second_class_sm_curr_rate',\n",
    "#  'uid_pt_d_app_second_class_rank_sm_curr_rate',\n",
    "#  'uid_pt_d_indu_name_counts',\n",
    "#  'uid_pt_d_indu_name_sm_curr_rate',\n",
    "#  'uid_pt_d_indu_name_rank_sm_curr_rate',\n",
    "#  'uid_pt_d_slot_id_counts',\n",
    "#  'uid_pt_d_slot_id_sm_curr_rate',\n",
    "#  'uid_pt_d_slot_id_rank_sm_curr_rate',\n",
    "#  'uid_pt_d_net_type_counts',\n",
    "#  'uid_pt_d_net_type_sm_curr_rate',\n",
    "#  'uid_pt_d_net_type_rank_sm_curr_rate',\n",
    "#  'uid_pt_d_slot_id_net_type_counts',\n",
    "#  'uid_pt_d_slot_id_net_type_sm_curr_rate',\n",
    "#  'uid_pt_d_slot_id_net_type_rank_sm_curr_rate']]\n",
    "\n",
    "df = df.merge(df_window0,on='index',how='left')\n",
    "df = df.merge(df_window1,on='index',how='left')\n",
    "df = df.merge(df_window2,on='index',how='left')\n",
    "# df = df.merge(df_uid,on='index',how='left')\n",
    "print(df.shape)\n",
    "df['label'] = df['label'].fillna(-1).astype(int)\n",
    "# for var in tqdm(df.columns):\n",
    "#     if str(df[var].dtype).find('float32')>-1:\n",
    "#         df[var] = df[var].astype(np.float16)\n",
    "del df_window0,df_window1,df_window2# ,df_uid\n",
    "gc.collect()\n",
    "print('loading data finish!')\n",
    "\n",
    "droplist = []\n",
    "set_tst =df.query('pt_d==8').copy()\n",
    "for var in df.columns:\n",
    "    if var not in ['index','uid','pt_d','label','id']:\n",
    "        if set_tst[var].nunique()<2:\n",
    "            droplist.append(var)\n",
    "print('droplist:',droplist)\n",
    "df = df.drop(droplist,axis=1)\n",
    "gc.collect()\n",
    "\n",
    "# #线下数据集的切分\n",
    "X_train = df[df[\"pt_d\"]<7].copy()\n",
    "y_train = X_train[\"label\"].astype('int32')\n",
    "X_valid = df[df[\"pt_d\"]==7]\n",
    "y_valid = X_valid[\"label\"].astype('int32')\n",
    "test_df = df[df[\"pt_d\"]==8].copy()\n",
    "# 筛选特征\n",
    "drop_fea = ['pt_d','label','communication_onlinerate','index','uid','id']\n",
    "feature= [x for x in X_train.columns if x not in drop_fea]\n",
    "print(len(feature))\n",
    "print(feature)\n",
    "\n",
    "#线下验证\n",
    "cate_fea = []\n",
    "clf = CatBoostClassifier(iterations=10000, depth=6,learning_rate=0.1, loss_function='Logloss',cat_features=cate_fea\n",
    "                        ,verbose=True,eval_metric='AUC',counter_calc_method='Full',task_type='GPU',metric_period=1000)\n",
    "clf.fit(\n",
    "    X_train[feature], y_train.astype('int32'),\n",
    "    eval_set=[(X_valid[feature],y_valid.astype('int32'))],\n",
    "    early_stopping_rounds=200,\n",
    "    verbose=True,\n",
    "    use_best_model=True,\n",
    ")\n",
    "joblib.dump(clf,'./models/ctb_local0917_0.pkl')\n",
    "y_predprob = clf.predict_proba(X_valid[feature])[:, 1] \n",
    "\n",
    "y_pre = clf.predict_proba(test_df[feature])[:, 1]  \n",
    "auc_score =roc_auc_score(y_valid, y_predprob)\n",
    "print(\"AUC Score (Valid): %f\" % auc_score)\n",
    "\n",
    "#查看模型的特征重要性\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "score = pd.DataFrame()\n",
    "score['fea_name'] = clf.feature_names_\n",
    "score['fea']=clf.feature_importances_\n",
    "score = score.sort_values(['fea'], ascending=False)\n",
    "temp = pd.DataFrame()\n",
    "temp = score[:60]\n",
    "color = cm.jet(temp['fea']/temp['fea'].max())\n",
    "plt.figure(figsize=(10, 15))\n",
    "plt.barh(temp['fea_name'],temp['fea'],height =0.8,color=color,alpha=0.8)\n",
    "plt.show()\n",
    "\n",
    "# 线上提交的模型训练\n",
    "clf1 = CatBoostClassifier(iterations=clf.best_iteration_, depth=6,learning_rate=0.1, loss_function='Logloss'\n",
    "                        ,eval_metric='AUC',counter_calc_method='Full',task_type='GPU',metric_period=50)\n",
    "clf1.fit(\n",
    "    df[df[\"pt_d\"]<=7][feature], df[df[\"pt_d\"]<=7]['label'].astype('int32'),\n",
    "    verbose=True,\n",
    "    use_best_model=True,\n",
    ")\n",
    "joblib.dump(clf1,'./models/ctb_sub0917_0.pkl')\n",
    "y_pre = clf1.predict_proba(test_df[feature])[:, 1]    \n",
    "\n",
    "res = pd.DataFrame()\n",
    "res['id'] = test_df['id'].astype('int32')\n",
    "res['probability'] = y_pre\n",
    "res.to_csv('baseline0917_0_{}.csv'.format(auc_score),index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_py3",
   "language": "python",
   "name": "conda_tensorflow2_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}